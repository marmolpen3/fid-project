---
title: "R Notebook"
output: html_notebook
---

# Bike Rental Data

Los sistemas de alquiler de bicicletas suelen recopilar información interesante como la duración, los puntos de salida y destino y el tiempo del viaje. Con el fin de mejorar la gestión, se propone anticipar la demanda que habrá en un determinado rango de tiempo. Teniendo en cuenta la franja horaria, el tipo de día (laborable o festivo), la climatología, etc.

Por lo tanto, el objetivo es predecir la demanda de bicicletas en una serie de franjas horarias, empleando el siguiente conjunto de [datos](https://www.kaggle.com/datasets/aguado/bike-rental-data-set-uci).

El resto del documento se organiza de la siguiente forma: en la sección 1 se realiza un estudio de los datos y su prepocesamiento.

## Preprocesamiento y análisis de los datos

Instalación de ***tidyverse*** para la manipulación de los datos y la visualización, de ***Visadat*** para búsqueda de valores nulos y de ***ggplot2*** para visualización.

```{r}
install.packages("visdat")
library(tidyverse)
library(visdat)
library(ggplot2)
```

Carga del dataset: subconjuto de entrenamiento. Estudio de los datos tal y como se obtienen de ***Kaggle***. Como veremos los datos están todos en una columna separados por ";".

```{r}
bikes <- read.csv("data/train.csv")
colnames(bikes)
dim(bikes)
```

#### Preprocesado de los datos

En primer lugar, separamos los datos por ";" con el fin de tener las columnas separadas y poder preprocesar y análizar correctamente los datos. La función *summary* nos ofrece un resumen por cada una de las variables presentes en el dataset.

```{r}
train_bikes <- read.table("data/train.csv", na.strings="", header=TRUE, sep=";", dec=".")
head(train_bikes)
colnames(train_bikes)
dim(train_bikes)
summary(train_bikes)
```

Como podemos observar el atributo id no aporta información relevante, por lo que vamos a proceder a eliminarlo. Por otro lado, el atributo count no tiene un nombre representativo, lo sustituiremos por num_bikes.

```{r}
train_bikes <- select(train_bikes, -id)
names(train_bikes)[11] <- "num_bikes"
head(train_bikes)
```

Tras estudiar las variables presentes en el conjunto de datos procedemos a la limpieza de los datos. El objetivo es encontrar valores perdidos (NA).

```{r}
# Preprocesamiento 1. Valores perdidos

# Búsqueda de valores NA
vis_miss(train_bikes);
# Esta función filtraría todos los ejemplos incompletos, si hubiera.
train_bikes <- train_bikes %>%
  filter(complete.cases(train_bikes))
```

En cuanto a la detección y eliminación de outliers, el primer paso es visualizar los valores que contienen ruido a través de una gráfica. Las columnas que estudiamos son aquellas que su valor no está limitado ( *temperatura, temperatura media, humedad, velocidad del viento*).

```{r}
# Preprocesamiento 2. Detección y eliminación de outliers
train_bikes_boxplot <- select(train_bikes, temp, atemp, humidity, windspeed)
boxplot(train_bikes_boxplot, col = rainbow(ncol(train_bikes_boxplot)))
boxplot.stats(train_bikes$windspeed)
```

La velocidad del viento (windspeed) es el único atributo que presenta outliers, por lo que se procede a eliminarlos.

```{r}
# Outliers en windspeed por encima de 32 km/h
outlier_min <- min(boxplot.stats(train_bikes$windspeed)$out)

bikes_without_liers <- train_bikes$windspeed[train_bikes$windspeed < outlier_min]

# Comprobación
boxplot(bikes_without_liers, horizontal = TRUE)
boxplot.stats(bikes_without_liers)

# Filtrado de dataframe
train_bikes <- filter(train_bikes, train_bikes$windspeed < outlier_min)

str(train_bikes)
head(train_bikes)
```

A pesar de que no hay outliers en la variable humedad, es un factor que puede afectar a la salud en un porcentaje menor al 30%. Por ello, vamos a eliminar todos los ejemplos cuya humedad registrada sea menor a esta.

```{r}
# Filtrado de dataframe
train_bikes <- filter(train_bikes, train_bikes$humidity > 30)

# Comprobación
boxplot(train_bikes$humidity, horizontal = TRUE)
```

Respecto al resto de variables que contiene el dataset, se debe comprobar que todos los ejemplos poseen valores dentro del rango permitido.

```{r}
range(train_bikes$year)
range(train_bikes$hour)
range(train_bikes$season)
range(train_bikes$holiday)
range(train_bikes$workingday)
range(train_bikes$weather)
```

Dataframe preprocesado para identificación de valores perdidos, detección y eliminación de outliersy comprobación del rango en variables estáticas.

```{r}
summary(train_bikes)
```

A continuación, se realiza el preprocesamiento para los datos de testeo.

```{r}
test_bikes <- read.table("data/test.csv", na.strings="", header=TRUE, sep=";", dec=".")
head(test_bikes)
colnames(test_bikes)
dim(test_bikes)
```

Eliminamos la columna id, ya que no aporta ningún valor en el testeo.

```{r}
test_bikes <- select(test_bikes, -id)
head(test_bikes)
```

Realizamos una búsqueda de valores indefinidos.

```{r}
# Preprocesamiento 1. Valores perdidos

# Búsqueda de valores NA
vis_miss(test_bikes);
# Esta función filtraría todos los ejemplos incompletos, si hubiera.
test_bikes <- test_bikes %>%
  filter(complete.cases(test_bikes))
```

```{r}
# Preprocesamiento 2. Detección y eliminación de outliers
test_bikes_boxplot <- select(test_bikes, temp, atemp, humidity, windspeed)
boxplot(test_bikes_boxplot, col = rainbow(ncol(test_bikes_boxplot)))
boxplot.stats(test_bikes$windspeed)
```

```{r}
# Outliers en windspeed por encima de 32 km/h
outlier_min <- min(boxplot.stats(test_bikes$windspeed)$out)

test_bikes_without_liers <- test_bikes$windspeed[test_bikes$windspeed < outlier_min]

# Comprobación
boxplot(test_bikes_without_liers, horizontal = TRUE)
boxplot.stats(test_bikes_without_liers)

# Filtrado de dataframe
test_bikes <- filter(test_bikes, test_bikes$windspeed < outlier_min)

str(test_bikes)
head(test_bikes)
```

Al igual que anteriormente, eliminamos los ejemplos cuya humedad sea inferior a 30.

```{r}
# Filtrado de dataframe
test_bikes <- filter(test_bikes, test_bikes$humidity > 30)

# Comprobación
boxplot(test_bikes$humidity, horizontal = TRUE)
```

```{r}
range(test_bikes$year)
range(test_bikes$hour)
range(test_bikes$season)
range(test_bikes$holiday)
range(test_bikes$workingday)
range(test_bikes$weather)
```

```{r}
summary(test_bikes)
```

#### Análisis y visualización de los datos

Comprobamos la homogeneidad de los datos: ¿Cuál es el registro de datos recopilados según la hora? ¿Cuál es el registro de datos recopilados según la temporada del año?

Observaremos que durante la temporada de vacaciones es menos probable que se alquilen bicicletas y por ello, es más complejo recopilar los datos de esos días. Por otro lado, el tiempo también influye en el dataset, para el peor temporal encontramos muchos menos registros.

```{r}
# Ejemplos disponibles según el año
train_bikes %>%
  group_by(year) %>% 
  count()

# Ejemplos disponibles según la hora del día
train_bikes %>%
  group_by(hour) %>% 
  count()

# Ejemplos disponibles según la temporada del año
train_bikes %>%
  group_by(season) %>% 
  count()

# Ejemplos disponibles para vacaciones
train_bikes %>%
  group_by(holiday) %>% 
  count()

# Ejemplos disponibles para días de trabajo
train_bikes %>%
  group_by(workingday) %>% 
  count()

# Ejemplos disponibles según el tiempo
train_bikes %>%
  group_by(weather) %>% 
  count()

```

¿Cuántas bicicletas se han alquilado según la hora del día?

```{r}
bikes_by_hour <- train_bikes %>%
  group_by(hour) %>%
  summarize(total_bikes_by_hour = sum(num_bikes))
  
ggplot(bikes_by_hour, aes(x = hour, y = total_bikes_by_hour)) +
  geom_bar(stat = "identity")
```

¿Cuántas bicicletas se han alquilado según la temporada del año?

```{r}
bikes_by_season <- train_bikes %>%
  group_by(season) %>%
  summarize(total_bikes_by_season = sum(num_bikes))
  
ggplot(bikes_by_season, aes(x = season, y = total_bikes_by_season)) +
  geom_bar(stat = "identity")
```

¿Cuántas bicicletas se han alquilado según el temporal?

```{r}
bikes_by_weather <- train_bikes %>%
  group_by(weather) %>%
  summarize(total_bikes_by_weather = sum(num_bikes))
  
ggplot(bikes_by_weather, aes(x = weather, y = total_bikes_by_weather)) +
  geom_bar(stat = "identity")
```

Porcentaje de bicicletas que se alquilan durante los días de trabajo.

```{r}

bikes_by_working_day <- train_bikes %>%
  group_by(workingday) %>%
  summarize(total_bikes_by_working_day = sum(num_bikes))

bike_count <- bikes_by_working_day$total_bikes_by_working_day

bike_percentage <- paste0(round(100 * bike_count/sum(bike_count), 2), "%")

pie(bike_count, labels = bike_percentage)

legend("topleft", legend = c( "No laboral", "Laboral"), fill =  c("white", "lightblue"))
```

Porcentaje de bicicletas que se alquilan durante los días de vacaciones.

```{r}

bikes_by_holiday <- train_bikes %>%
  group_by(holiday) %>%
  summarize(total_bikes_by_holiday = sum(num_bikes))

bike_count <- bikes_by_holiday$total_bikes_by_holiday

bike_percentage <- paste0(round(100 * bike_count/sum(bike_count), 2), "%")

pie(bike_count, labels = bike_percentage)

legend("topleft", legend = c( "No vacaciones", "Vacaciones"), fill =  c("white", "lightblue"))
```

¿Cuántas bicicletas se han alquilado según el año?

```{r}

#bikes_by_year_hour <- train_bikes %>%
#  group_by(hour) %>%
#  group_by(year) %>%
#  summarize(total_bikes_by_year_hour = sum(num_bikes))

#hours <- c(0:23)
#hours

#ggplot(bikes_by_year_hour, aes(x = train_bikes$hour, y = total_bikes_by_year_hour, group = year)) + geom_line()
```

Porcentaje de bicicletas alquiladas según la hora del día.

```{r}

```

Búsqueda de relación lineal: dibujar el número de bicicletas en función del resto de variables.

```{r}
```

## Visualización

Instalación de ggplot2

```{r}
# So, now...what do we looking for?
```

```{r}

```

## Algoritmo lm()

Modelo realizado con lm como en la práctica 3 (regresión).

Y predicción con ese modelo.

## Algoritmos Caret

En este punto, vamos a generar distintos modelos con varios métodos que incluye el paquete Caret. A partir de estos modelos, los cuales son creados a partir del subconjunto de entrenamiento, se procederá a la predicción del número de bicicletas alquiladas para cada uno de los ejemplos del subconjunto de prueba.

Antes de comenzar, se carga el paquete Caret.

```{r}
library(caret)
```

A continuación, creamos la función de control mediante `trainControl`. Con esta función vamos a controlar cómo se crearán los modelos.

```{r}
fitControl <- trainControl(
  method = "cv",
  number = 10,
  savePredictions = TRUE,
  verbose = FALSE
)
```

Con esto, tomaremos el subconjunto de entrenamiento, el cual se usará para preparar los distintos modelos generados con el paquete Caret.

```{r}
head(train_bikes)
```

### Random Forest

Acto seguido, se procede a crear un primer modelo de regresión, utilizando el método Random Forest.

```{r}
model_rf_reg <- train(num_bikes ~ .,
                      train_bikes,
                      method = "rf",
                      ntree = 5,
                      trControl = fitControl)

model_rf_reg
```

### xgbTree

Una de las librerías más populares de aprendizaje automático, y que ha demostrado una gran eficiencia y escalabilidad es XGBoost. El paquete caret incluye entre sus funciones una implementación de la API de XGBoost para R. Se trata de la función xgbTree.

Como tercera opción a comparar, se va a hacer uso de este método, tomando como punto de partida el modelo por defecto con todas las variables predictoras.

```{r}
model_xgbTree <- train(
  num_bikes ~ .,
  train_bikes,
  method = "xgbTree",
  trControl = fitControl)
```

```{r}
model_xgbTree
```

El modelo resultante obtenido fija como parámetros de afinación 150 árboles, con una profundidad máxima 3, tasa de aprendizaje de 40% y un 80% de las columnas usadas por árbol.

Además, el parámetro min_child_weight indica la cantidad mínima de datos que deben estar presentes en los nodos hoja del árbol. Esto significa que si un nodo tiene un peso menor que el valor especificado, se convertirá en un nodo hoja y no se dividirá más. Por tanto cuanto mayor sea este valor, más simple será el árbol resultante. En este caso el valor es 1.

Por último, el parámetro subsample representa el porcentaje de observaciones a usar en cada iteración del entrenamiento, que corresponde al 100%.

```{r}
default_tune_grid <- expand.grid(
  nrounds = 150,
  max_depth = 3,
  eta = 0.4,
  gamma = 0,
  colsample_bytree = 0.8,
  min_child_weight = 1,
  subsample = 1
  )

model_xgbTree <- train(
  num_bikes ~ .,
  train_bikes,
  method = "xgbTree",
  tuneGrid = default_tune_grid,
  trControl = fitControl)

model_xgbTree
```

El R-squared obtenido es de 0.9176 para este caso.

A continuación, se procede a realizar una serie de combinaciones de los parámetros comentados anteriormente para mejorar el error:

```{r}
tune_grid = expand.grid(
  nrounds = 150,
  max_depth = 5,
  eta = 0.1,
  gamma = 0,
  colsample_bytree = 0.8,
  min_child_weight = 1,
  subsample = 0.8
  )

model_tuned_xgbTree <- train(
  num_bikes ~ .,
  train_bikes,
  method = "xgbTree",
  tuneGrid = tune_grid,
  trControl = fitControl)

model_tuned_xgbTree
```

```{r}
tune_grid = expand.grid(
  nrounds = 150,
  max_depth = 7,
  eta = 0.1,
  gamma = 0.8,
  colsample_bytree = 1,
  min_child_weight = 0,
  subsample = 1
  )

model_tuned_xgbTree <- train(
  num_bikes ~ .,
  train_bikes,
  method = "xgbTree",
  tuneGrid = tune_grid,
  trControl = fitControl)

model_tuned_xgbTree
```

Tras ejecutar diferentes pruebas se consigue optimizar el R-squared hasta un valor de 0.943 aproximandamente.

Para ello, se han aplicado los siguientes parámetros de afinación: 150 árboles, con profundidad máxima 7, tasa de aprendizaje del 10%, el 100% de columnas usadas por árbol y un 100% de observaciones usadas en cada iteración del entrenamiento.

Aunque aumenta la complejidad con respecto al modelo anterior, también aumenta la precisión, como se puede observar en el valor de R-squared.

Por último, se comprueba si el algoritmo mejora los resultados sin considerar los atributos holiday, workingday, weather y temp. El valor de R-squared disminuye en la misma medida que se comprobó para el modelo Random Forest.

```{r}
model_tuned_xgbTree_2 <- train(
  num_bikes ~ .,
  train_bikes %>%
    select(-holiday, -workingday, -weather, -temp),
  method = "xgbTree",
  tuneGrid = expand.grid(
    nrounds = 150, max_depth = 7, eta = 0.1, gamma = 0.8, colsample_bytree = 1, min_child_weight = 0, subsample = 1
  ),
  trControl = fitControl)

model_tuned_xgbTree_2
```

Tras probar a eliminar los atributos realizando combinaciones diferentes, se observa que manteniendo los atributos weather y workingday, el valor de R-squared se mantiene relativamente estable, aunque no alcanza al obtenido sin eliminar variables.

```{r}
model_tuned_xgbTree_3 <- train(
  num_bikes ~ .,
  train_bikes %>%
    select(-holiday, -temp),
  method = "xgbTree",
  tuneGrid = expand.grid(
    nrounds = 150, max_depth = 7, eta = 0.1, gamma = 0.8, colsample_bytree = 1, min_child_weight = 0, subsample = 1
  ),
  trControl = fitControl)

model_tuned_xgbTree_3
```

Finalmente, al evaluar los modelos que se han creado, se obtiene que el mejor modelo es el que tiene aplicados los parámetros de afinación y eliminadas las variables holiday y temp (TUNED_XGB3).

```{r}
resamps_rf <- resamples(list(
  DEFAULT_XGB = model_xgbTree,
  TUNED_XGB = model_tuned_xgbTree,
  TUNED_XGB2 = model_tuned_xgbTree_2,
  TUNED_XGB3 = model_tuned_xgbTree_3
))
summary(resamps_rf, metric = "Rsquared")
bwplot(resamps_rf, metric = "Rsquared")
```

Aquí se representa la predicción correspondiente modelo seleccionado:

```{r}
predict(model_tuned_xgbTree_3, newdata = head(train_bikes))

plot(x=predict(model_tuned_xgbTree_3), y= train_bikes$num_bikes,
     xlab='Predicted Values',
     ylab='Actual Values',
     main='Predicted vs. Actual Values')
abline(a = 0, b = 1, col = "red", lwd = 2)
```

## Comparativa de modelos
