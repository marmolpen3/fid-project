---
title: "R Notebook"
output: html_notebook
---

# Bike Rental Data

Los sistemas de alquiler de bicicletas suelen recopilar información interesante como la duración, los puntos de salida y destino y el tiempo del viaje. Con el fin de mejorar la gestión, se propone anticipar la demanda que habrá en un determinado rango de tiempo. Teniendo en cuenta la franja horaria, el tipo de día (laborable o festivo), la climatología, etc. Las variables que contiene el data set son las siguientes:

-   id: identificador (**variable cuantitativa discreta**)

-   year: años (2011 y 2012) (**variable cuantitativa discreta**)

-   hour: hora del día (0 to 23) (**variable cuantitativa discreta**)

-   season: 1 = invierno, 2 = primavera, 3 = verano, 4 = otoño (**variable cuantitativa discreta**)

-   holiday: si fue un día de vacaciones (**variable cuantitativa discreta**)

-   workingday: si fue un día de trabajo (**variable cuantitativa discreta**)

-   weather: tres categorías en rango de mejor a peor tiempo (1 a 3) (**variable cuantitativa discreta**)

-   temp: temperatura en grados Celsius (**variable cuantitativa continua**)

-   atemp: sensación de temperatura en grados Celsius (**variable cuantitativa continua**)

-   humidity: humedad relativa (**variable cuantitativa continua**)

-   windspeed: velocidad del viento (km/h) (**variable cuantitativa continua**)

-   num_bikes: número total de bicicletas alquiladas en para esas condiciones (**variable cuantitativa discreta**)

Por lo tanto, el objetivo es predecir la demanda de bicicletas en una serie de franjas horarias, empleando el siguiente conjunto de [datos](https://www.kaggle.com/datasets/aguado/bike-rental-data-set-uci).

El resto del documento se organiza de la siguiente forma: en la sección 1 se realiza un estudio de los datos y su preprocesamiento.

## Preprocesamiento y análisis de los datos

Instalación de ***tidyverse*** para la manipulación de los datos y la visualización, de ***Visadat*** para búsqueda de valores nulos y de ***ggplot2*** para visualización.

```{r}
library(tidyverse)
library(visdat)
library(ggplot2)
library(corrplot)
```

Carga del dataset: subconjunto de entrenamiento. Estudio de los datos tal y como se obtienen de ***Kaggle***. Como veremos los datos están todos en una columna separados por ";".

```{r}
bikes <- read.csv("data/train.csv")
colnames(bikes)
dim(bikes)
```

#### Preprocesado de los datos

En primer lugar, separamos los datos por ";" con el fin de tener las columnas separadas y poder preprocesar y analizar correctamente los datos. La función *summary* nos ofrece un resumen por cada una de las variables presentes en el dataset.

```{r}
train_bikes <- read.table("data/train.csv", na.strings="", header=TRUE, sep=";", dec=".")
head(train_bikes)
colnames(train_bikes)
dim(train_bikes)
summary(train_bikes)
```

Como podemos observar el atributo id no aporta información relevante, por lo que vamos a proceder a eliminarlo. Por otro lado, el atributo *count* no tiene un nombre representativo, lo sustituiremos por *num_bikes*.

```{r}
train_bikes <- select(train_bikes, -id)
names(train_bikes)[11] <- "num_bikes"
head(train_bikes)
```

Tras estudiar las variables presentes en el conjunto de datos procedemos a la limpieza de los datos. El objetivo es encontrar valores perdidos (NA).

```{r}
# Preprocesamiento 1. Valores perdidos

# Búsqueda de valores NA
vis_miss(train_bikes);
# Esta función filtraría todos los ejemplos incompletos, si hubiera.
train_bikes <- train_bikes %>%
  filter(complete.cases(train_bikes))
```

En cuanto a la detección y eliminación de outliers, el primer paso es visualizar los valores que contienen ruido a través de una gráfica. Las columnas que estudiamos son aquellas que su valor no está limitado ( *temperatura, temperatura media, humedad, velocidad del viento*).

```{r}
# Preprocesamiento 2. Detección y eliminación de outliers
train_bikes_boxplot <- select(train_bikes, temp, atemp, humidity, windspeed)
boxplot(train_bikes_boxplot, col = rainbow(ncol(train_bikes_boxplot)))
boxplot.stats(train_bikes$windspeed)
```

La velocidad del viento (windspeed) es el único atributo que presenta outliers, por lo que se procede a eliminarlos.

```{r}
# Outliers en windspeed por encima de 32 km/h
outlier_min <- min(boxplot.stats(train_bikes$windspeed)$out)

bikes_without_liers <- train_bikes$windspeed[train_bikes$windspeed < outlier_min]

# Comprobación
boxplot(bikes_without_liers, horizontal = TRUE)
boxplot.stats(bikes_without_liers)

# Filtrado de dataframe
train_bikes <- filter(train_bikes, train_bikes$windspeed < outlier_min)

str(train_bikes)
head(train_bikes)
```

A pesar de que no hay outliers en la variable humedad, es un factor que puede afectar a la salud en un porcentaje menor al 30%. Por ello, vamos a eliminar todos los ejemplos cuya [humedad](https://es.wikipedia.org/wiki/Humedad_relativa) registrada sea menor a esta.

```{r}
# Filtrado de dataframe
train_bikes <- filter(train_bikes, train_bikes$humidity > 30)

# Comprobación
boxplot(train_bikes$humidity, horizontal = TRUE)
```

Respecto al resto de variables que contiene el dataset, se debe comprobar que todos los ejemplos poseen valores dentro del rango permitido.

```{r}
range(train_bikes$year)
range(train_bikes$hour)
range(train_bikes$season)
range(train_bikes$holiday)
range(train_bikes$workingday)
range(train_bikes$weather)
```

Dataframe preprocesado para identificación de valores perdidos, detección y eliminación de outliers y comprobación del rango en variables estáticas.

```{r}
summary(train_bikes)
```

A continuación, se realiza el preprocesamiento para los datos del subconjunto de test.

```{r}
test_bikes <- read.table("data/test.csv", na.strings="", header=TRUE, sep=";", dec=".")
head(test_bikes)
colnames(test_bikes)
dim(test_bikes)
```

Eliminamos la columna id, ya que no aporta ningún valor en el testeo.

```{r}
test_bikes <- select(test_bikes, -id)
head(test_bikes)
```

Realizamos una búsqueda de valores indefinidos.

```{r}
# Preprocesamiento 1. Valores perdidos

# Búsqueda de valores NA
vis_miss(test_bikes);
# Esta función filtraría todos los ejemplos incompletos, si hubiera.
test_bikes <- test_bikes %>%
  filter(complete.cases(test_bikes))
```

```{r}
# Preprocesamiento 2. Detección y eliminación de outliers
test_bikes_boxplot <- select(test_bikes, temp, atemp, humidity, windspeed)
boxplot(test_bikes_boxplot, col = rainbow(ncol(test_bikes_boxplot)))
boxplot.stats(test_bikes$windspeed)
```

```{r}
# Outliers en windspeed por encima de 32 km/h
outlier_min <- min(boxplot.stats(test_bikes$windspeed)$out)

test_bikes_without_liers <- test_bikes$windspeed[test_bikes$windspeed < outlier_min]

# Comprobación
boxplot(test_bikes_without_liers, horizontal = TRUE)
boxplot.stats(test_bikes_without_liers)

# Filtrado de dataframe
test_bikes <- filter(test_bikes, test_bikes$windspeed < outlier_min)

str(test_bikes)
head(test_bikes)
```

Al igual que anteriormente, eliminamos los ejemplos cuya [humedad](https://es.wikipedia.org/wiki/Humedad_relativa) sea inferior a 30.

```{r}
# Filtrado de dataframe
test_bikes <- filter(test_bikes, test_bikes$humidity > 30)

# Comprobación
boxplot(test_bikes$humidity, horizontal = TRUE)
```

```{r}
range(test_bikes$year)
range(test_bikes$hour)
range(test_bikes$season)
range(test_bikes$holiday)
range(test_bikes$workingday)
range(test_bikes$weather)
```

```{r}
summary(test_bikes)
```

#### Análisis y visualización de los datos

Comprobamos la homogeneidad de los datos: ¿Cuál es el registro de datos recopilados según la hora? ¿Cuál es el registro de datos recopilados según la temporada del año?

Observaremos que durante la temporada de vacaciones es menos probable que se alquilen bicicletas y por ello, es más complejo recopilar los datos de esos días. Por otro lado, el tiempo también influye en el dataset, para el peor temporal encontramos muchos menos registros.

```{r}
# Ejemplos disponibles según el año
train_bikes %>%
  group_by(year) %>% 
  count()

# Ejemplos disponibles según la hora del día
train_bikes %>%
  group_by(hour) %>% 
  count()

# Ejemplos disponibles según la temporada del año
train_bikes %>%
  group_by(season) %>% 
  count()

# Ejemplos disponibles para vacaciones
train_bikes %>%
  group_by(holiday) %>% 
  count()

# Ejemplos disponibles para días de trabajo
train_bikes %>%
  group_by(workingday) %>% 
  count()

# Ejemplos disponibles según el tiempo
train_bikes %>%
  group_by(weather) %>% 
  count()

```

¿Cuántas bicicletas se han alquilado según la hora del día?

```{r}
bikes_by_hour <- train_bikes %>%
  group_by(hour) %>%
  summarize(total_bikes_by_hour = sum(num_bikes))
  
ggplot(bikes_by_hour, aes(x = hour, y = total_bikes_by_hour)) +
  geom_bar(stat = "identity")
```

¿Cuántas bicicletas se han alquilado según la temporada del año?

```{r}
bikes_by_season <- train_bikes %>%
  group_by(season) %>%
  summarize(total_bikes_by_season = sum(num_bikes))
  
ggplot(bikes_by_season, aes(x = season, y = total_bikes_by_season)) +
  geom_bar(stat = "identity")
```

¿Cuántas bicicletas se han alquilado según el estado del tiempo?

```{r}
bikes_by_weather <- train_bikes %>%
  group_by(weather) %>%
  summarize(total_bikes_by_weather = sum(num_bikes))
  
ggplot(bikes_by_weather, aes(x = weather, y = total_bikes_by_weather)) +
  geom_bar(stat = "identity")
```

Porcentaje de bicicletas que se alquilan durante los días de trabajo.

```{r}

bikes_by_working_day <- train_bikes %>%
  group_by(workingday) %>%
  summarize(total_bikes_by_working_day = sum(num_bikes))

bike_count <- bikes_by_working_day$total_bikes_by_working_day

bike_percentage <- paste0(round(100 * bike_count/sum(bike_count), 2), "%")
bike_count
bike_percentage

pie(bike_count, labels = bike_percentage)

legend("topleft", legend = c( "No laboral", "Laboral"), fill =  c("white", "lightblue"))
```

Porcentaje medio de bicicletas que se alquilan si estamos en días de vacaciones o no.

```{r}

bikes_by_holiday <- train_bikes %>%
  group_by(holiday) %>%
  summarize(total_bikes_by_holiday = sum(num_bikes))

bike_count <- bikes_by_holiday$total_bikes_by_holiday

samples_holiday <- train_bikes %>%
                    group_by(holiday) %>% 
                      count()

a_no_holiday <- bike_count[1]/samples_holiday[1,2]

a_holiday <- bike_count[2]/samples_holiday[2,2]

a_bike_count <- data.frame(c(a_no_holiday, a_holiday))

bike_percentage <- paste0(round(100 * a_bike_count/sum(a_bike_count), 2), "%")

result <- data.frame(bike_percentage[1], bike_percentage[2])
colnames(result) <- c("non vacation", "vacation")

result
```

## Algoritmo lm()

El conjunto de datos que se está tratando contiene más de dos variables cuantitativas que se deben emplear en la predicción de bicicletas. Para aplicar un modelo de regresión lineal multivariable es necesario realizar un estudio de la relación lineal existente entre las variables, en concreto el número de bicicletas (variable a predecir) en función del resto de columnas. El análisis comienza con la creación de un diagrama de dispersión que nos muestra la relación entre las variables.

```{r}
# Diagrama de dispersión para el número de bicicletas frente al resto de variables

plot(num_bikes ~ ., train_bikes)
```

Observamos que no es adecuado aplicar modelos de regresión lineal, pues la distribución no parece indicar una posible relación lineal entre las variables. A pesar de ello, estudiamos la [correlación](https://www.cienciadedatos.net/documentos/24_correlacion_y_regresion_lineal) entre las variables para conocer como de relacionadas están las columnas.

Todos los valores del índice de correlación r varían entre [-1, 1], siendo -1 una correlación negativa perfecta y el 1 correlación positiva perfecta.

-   correlación **nula**: r \< \|0.1\|

-   correlación **pequeña**: \|0.1\| \< r \<= \|0.3\|

-   correlación **mediana** : \|0.3\| \< r \<= \|0.5\|

-   correlación **moderada** : \|0.5\| \< r \<= \|0.7\|

-   correlación **alta o muy alta**: r \> \|0.7\|

```{r}
# Estudio de la normalización de las variables
qqnorm(train_bikes$num_bikes, main = "Num bikes", col = "darkred")
qqline(train_bikes$num_bikes)
qqnorm(train_bikes$hour, main = "Hour", col = "blue")
qqline(train_bikes$hour)
```

Debido a que las variables cuantitativas que contiene el dataset no se distribuyen de forma normal, se ha empleado el coeficiente de Spearman para el cálculo de la correlación.

```{r}
# Matriz de correlación entre las variables cuantitativas
cor_datos_cuanti <- round(cor(train_bikes,  method = "spearman"), digits = 2)
cor_datos_cuanti

M <- round(cor(train_bikes,  method = "spearman"), digits=2)

corrplot(M, method = "number", tl.cex = 0.7,number.cex = 0.8)  

```

Al examinar el mapa con los valores de la correlación tenemos que el mayor r obtenido es de 0.53, correlación moderada entre horas y número de bicicletas.

Aunque aplicar un modelo de regresión lineal no tiene sentido para este conjunto de datos, se va generar el modelo lineal a modo de estudio del problema, con el fin de demostrar que no aporta valor realizar una predicción de este tipo. En la siguiente sección, se indagará sobre modelos de regresión no lineal obteniendo unos mejores resultados.

```{r}
# Construcción del modelo en base al resto de variables 
lm_bikes <- lm(num_bikes ~ ., data = train_bikes)

# Resumen del modelo
summary(lm_bikes)
```

Analizando el resumen del modelo, encontramos que *holiday*, *workingday*, *weather*, *temp* tienen bajo nivel de significancia. Por ello, vamos a omitir estas columnas tanto en la generación del modelo como en la posterior predicción.

```{r}
train_bikes_short <- select(train_bikes, -holiday, -workingday, -weather, -temp)

head(train_bikes_short)
```

A pesar de eliminar estos atributos poco significativos, el valor de R-squared no varía.

```{r}
# Construcción del modelo en base al resto de variables 
lm_bikes_short <- lm(num_bikes ~ ., data = train_bikes_short)

# Resumen del modelo
summary(lm_bikes_short)
```

```{r}
plot(lm_bikes_short$fitted.values,  lm_bikes_short$residuals,
     xlab = "Valores ajustados", ylab = "Residuos")
```

```{r}
qqnorm(lm_bikes_short$residuals, ylab = "Cuantiles residuales")
```

Realizamos la predicción del número de bicicletas con el primer ejemplo del dataset.

```{r}
# Predecimos el número de bicicletas del primer ejemplo del dataset
sample_1 <- train_bikes %>%
  slice_head(n = 1) %>%
  select(-holiday, -workingday, -weather, -temp)

expected_value <- train_bikes %>%
                    slice_head(n = 1)
  
expected_value[1, 11]
predict(lm_bikes_short, sample_1)

```

Se puede observar que hay un importante desajuste en la predicción, siendo esta de 325 bicicletas para un valor esperado de 133.

## Algoritmos Caret

En este punto, vamos a generar distintos modelos con varios métodos que incluye el paquete Caret. A partir de estos modelos, los cuales son creados a partir del subconjunto de entrenamiento, se procederá a la predicción del número de bicicletas alquiladas para cada uno de los ejemplos del subconjunto de prueba.

Antes de comenzar, se carga el paquete Caret.

```{r}
library(caret)
```

A continuación, creamos la función de control mediante `trainControl`. Con esta función vamos a controlar cómo se entrenarán los modelos.

```{r}
fitControl <- trainControl(
  method = "cv",
  number = 10
)
```

Con esto, tomaremos el subconjunto de entrenamiento, el cual se usará para preparar los distintos modelos generados con el paquete Caret.

```{r}
head(train_bikes)
```

### Random Forest

Acto seguido, se procede a crear un primer modelo de regresión, utilizando el método Random Forest. Para ello, se ha decidido optar por parametrizar el argumento ntree con un valor de 5, ya que el algoritmo toma un tiempo de ejecución considerable para mayores superiores sin que tampoco mejore el rendimiento.

También se ha optado por entrenar dos modelos y elegir el mejor: uno en el que se considere a todas las variables como predictoras, y otro en el que se eliminen aquellas menos significativas a priori, tal como se vio en el apartado anterior.

En este primer paso también se opta por personalizar los parámetros del algoritmo Random Forest, pasando los parámetros como argumento tuneGrid.

```{r}
rfGrid <- expand.grid(mtry = c(2,4,6,8,10))

model_rf_reg <- train(num_bikes ~ .,
                      train_bikes,
                      method = "rf",
                      ntree = 5,
                      tuneGrid = rfGrid,
                      trControl = fitControl,
                      metric = "Rsquared")

model_rf_reg
```

En el segundo caso, se hace ejecuta el mismo algoritmo pero sin considerar los atributos holiday, workingday, weather y temp.

```{r}
rfGrid <- expand.grid(mtry = c(2,3,4,5,6))

model_rf_reg2 <- train(num_bikes ~ .,
                      train_bikes %>%
                        select(-holiday, -workingday, -weather, -temp),
                      method = "rf",
                      ntree = 5,
                      tuneGrid = rfGrid,
                      trControl = fitControl,
                      metric = "Rsquared")

model_rf_reg2
```

Como se puede observar, el mejor modelo obtenido limitando las variables predictoras no supera al que se obtiene cuando se las considera a todas.

-   Modelo 1: R-squared de 0.9225

-   Modelo 2: R-squared de 0.7301

```{r}
resamps_rf <- resamples(list(
  RF1 = model_rf_reg,
  RF2 = model_rf_reg2
))

summary(resamps_rf, metric = "Rsquared")
bwplot(resamps_rf, metric = "Rsquared")
```

De este modo, se opta por el primer modelo para realizar una predicción de prueba, al igual que se hizo con la regresión lineal.

```{r}
# Predecimos el número de bicicletas del primer ejemplo del dataset
sample_1 <- train_bikes %>%
  slice_head(n = 6)

expected_value <- train_bikes %>%
                    slice_head(n = 6)
  
cat("Valores originales:\n")
expected_value[1:6, 11]
cat("Predicción:\n")
floor(predict(model_rf_reg, sample_1))
```

A través del modelo generado con Random Forest se obtiene una predicción algo más ajustada al caso esperado. Por seguir con el primer ejemplo del conjunto de entrenamiento, la predicción indica 148 bicicletas alquiladas para las 133 esperadas por el caso real.

### xgbTree

```{r}
model_xgbTree <- train(
  num_bikes ~ .,
  bikes_train_set,
  method = "xgbTree",
  trControl = fitControl)
```

```{r}
model_xgbTree
```

### gbm

En este caso se utiliza el algoritmo Stochastic Gradient Boosting mediante el método gbm del paquete Caret. Aquí se ha optado por ver qué modelo retorna el método sin parametrizar, con los valores por defecto y, posteriormente, ver cómo rinde el modelo generado tras imputar de forma personalizada los valores de los parámetros del algoritmo.

En este primer fragmento de código, se utilizan los parámetros por defecto.

```{r}
model_gbm_reg <- train(
  num_bikes ~ .,
  train_bikes,
  method = "gbm",
  trControl = fitControl,
  metric = "Rsquared",
  verbose = FALSE)

model_gbm_reg
```

```{r}
densityplot(model_gbm_reg, pch="|")
```

El modelo se obtiene fijando el learning rate (shrinkage) constante a 0.1 para 150 árboles y un máximo de nodos por árbol de 3, parámetros n.tree e interaction.depth respectivamente.

El R-squared obtenido es de 0.8654 para este caso.

Acto seguido, se genera un segundo modelo parametrizado, basándonos en las investigaciones que se han realizado para este algoritmo: [referencia 1](https://www.listendata.com/2015/07/gbm-boosted-models-tuning-parameters.html) y [referencia 2](https://stackoverflow.com/questions/15613332/using-caret-package-to-find-optimal-parameters-of-gbm).

El shrinkage corresponde al learning rate, lo que se puede considerar la velocidad de aprendizaje del algoritmo. Este parámetro está relacionado con el tamaño del conjunto de ejemplos de entrenamiento: el learning rate debe ser pequeño en datasets pequeños y utilizar un valor de 0.1 (el valor por defecto) para conjuntos que superen los 10.000 registros.

Por otro lado, a menor learning rate, mayor deberá ser el número de árboles, esto es, el valor del parámetro n.tree, por lo que el parámetro se ajustará en un rango y se tomará el mejor valor. Aunque a mayor número de árboles también se obtiene una mejora en la reducción del error, también se incurre en un posible sobreajuste del modelo.

Por último, el valor de interaction.depth suele ser un valor bajo, pero en [referencia 2](https://stackoverflow.com/questions/15613332/using-caret-package-to-find-optimal-parameters-of-gbm) se recomienda utilizar la fórmula que, finalmente, se aplica en el siguiente fragmente de código, donde se genera el nuevo modelo.

```{r}
# Fórmulas obtenidas en la referencia 2
shrinkage <- max(0.01, 0.1 * min(1, nrow(train_bikes) / 10000))
interaction.depth <- floor(sqrt(ncol(train_bikes)))

# Ajuste de parámetros personalizados
gbmGrid <- expand.grid(
  interaction.depth = interaction.depth,
  n.trees = (1:10)*50,
  shrinkage = shrinkage,
  n.minobsinnode = 10
)

model_gbm_reg2 <- train(
  num_bikes ~ .,
  train_bikes,
  method = "gbm",
  tuneGrid = gbmGrid,
  trControl = fitControl,
  metric = "Rsquared",
  verbose = FALSE)

model_gbm_reg2
```

```{r}
densityplot(model_gbm_reg2, pch="|")
```

Por último, podemos ver qué modelo es mejor de los dos obtenidos con el método gbm.

```{r}
resamps_gbm <- resamples(list(
  GBM1 = model_gbm_reg,
  GBM2 = model_gbm_reg2
))

summary(resamps_gbm, metric = "Rsquared")
bwplot(resamps_gbm, metric = "Rsquared")
```

Tras esto, nos decantamos por el segundo modelo, el cual se obtiene ajustando los parámetros. Finalmente, realizamos también una estimación de prueba como en los casos anteriores.

```{r}
# Predecimos el número de bicicletas del primer ejemplo del dataset
sample_1 <- train_bikes %>%
  slice_head(n = 6)

expected_value <- train_bikes %>%
                    slice_head(n = 6)

cat("Valores originales:\n")  
expected_value[1:6, 11]
cat("Predicción:\n")
floor(predict(model_gbm_reg2, sample_1))
```

Se puede concluir este apartado comentando la mejora en la predicción, aunque se siguen observando algunos desajustes.

## Comparativa de modelos

En esta última sección se va a proceder a comparar los modelos generados y seleccionados con los distintos métodos incluidos en el paquete Caret que han sido utilizados previamente.

Para esto, se utilizará la función resamples y se observará qué modelo ofrece mejor rendimiento y un menor error.

```{r}
resamps <- resamples(list(
  RF = model_rf_reg,
  GBM = model_gbm_reg2
))

summary(resamps)
```

Vamos a observar el rendimiento en base a las métricas: R-squared, RMSE y MAE.

```{r}
summary(resamps, metric = "Rsquared")
bwplot(resamps, metric = "Rsquared")
```

```{r}
summary(resamps, metric = "RMSE")
bwplot(resamps, metric = "RMSE")
```

```{r}
summary(resamps, metric = "MAE")
bwplot(resamps, metric = "MAE")
```

En función de todas estas medidas, Random Forest presenta un mejor rendimiento y mayor precisión con respecto a gbm para el conjunto de datos de entrenamiento. Aunque la diferencia es mínima, nos ayudaremos de la visualización para determinar la elección del modelo de predicción definitivo.

Vamos a graficar la predicción con cada uno de estos modelos junto con el valor real de cada ejemplo, de modo que podamos ver de manera visual las desviaciones. Para ello, en primer lugar se ha realizado una selección de ejemplos del subconjunto de entrenamiento, en el que se dispone del número de bicicletas alquiladas. Posteriormente, se implementa una función que recibe el modelo y el conjunto de datos originales para los que se realiza la predicción.

Como resultado, se obtiene la gráfica con los valores superpuestos.

```{r}
sample_train_bikes <- train_bikes %>%
  filter(num_bikes < 400) %>%
  slice_head(n = 100)

plot_real_and_predict <- function(model, data) {
  sample_predict <- data %>%
    select(-num_bikes)
  
  res_predict <- predict(model, sample_predict)
  res_predict <- data.frame(floor(res_predict))
  names(res_predict)[1] <- "num_bikes"
  
  ggplot() +
  geom_area(data = data,
            aes(x = 1:nrow(data), y = num_bikes),
            alpha = 0.6,
            color = "red",
            fill = "red") +
  geom_area(data = res_predict,
            aes(x = 1:nrow(res_predict), y = num_bikes),
            alpha = 0.4,
            color = "blue",
            fill = "blue") +
  labs(x = "Casos")
}
```

Vamos a observar la predicción para el modelo de Random Forest.

```{r}
plot_real_and_predict(model_rf_reg, sample_train_bikes)
```

En esta ocasión, se visualiza la predicción para el modelo gbm.

```{r}
plot_real_and_predict(model_gbm_reg2, sample_train_bikes)
```
