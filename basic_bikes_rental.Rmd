---
title: "R Notebook"
output: html_notebook
---

# Bike Rental Data

Los sistemas de alquiler de bicicletas suelen recopilar información interesante como la duración, los puntos de salida y destino y el tiempo del viaje. Con el fin de mejorar la gestión, se propone anticipar la demanda que habrá en un determinado rango de tiempo. Teniendo en cuenta la franja horaria, el tipo de día (laborable o festivo), la climatología, etc. Las variables que contiene el data set son las siguientes:

-   id: identificador (**variable cuantitativa discreta**)

-   year: años (2011 y 2012) (**variable cuantitativa discreta**)

-   hour: hora del día (0 to 23) (**variable cuantitativa discreta**)

-   season: 1 = invierno, 2 = primavera, 3 = verano, 4 = otoño (**variable cuantitativa discreta**)

-   holiday: si fue un día de vacaciones (**variable cuantitativa discreta**)

-   workingday: si fue un día de trabajo (**variable cuantitativa discreta**)

-   weather: tres categorías en rango de mejor a peor tiempo (1 a 3) (**variable cuantitativa discreta**)

-   temp: temperatura en grados Celsius (**variable cuantitativa continua**)

-   atemp: sensación de temperatura en grados Celsius (**variable cuantitativa continua**)

-   humidity: humedad relativa (**variable cuantitativa continua**)

-   windspeed: velocidad del viento (km/h) (**variable cuantitativa continua**)

-   num_bikes: número total de bicicletas alquiladas en para esas condiciones (**variable cuantitativa discreta**)

Por lo tanto, el objetivo es predecir la demanda de bicicletas en una serie de franjas horarias, empleando el siguiente conjunto de [datos](https://www.kaggle.com/datasets/aguado/bike-rental-data-set-uci).

El resto del documento se organiza de la siguiente forma: en la sección 1 se realiza un estudio de los datos y su prepocesamiento.

## Preprocesamiento y análisis de los datos

Instalación de ***tidyverse*** para la manipulación de los datos y la visualización, de ***Visadat*** para búsqueda de valores nulos y de ***ggplot2*** para visualización.

```{r}
library(tidyverse)
library(visdat)
library(ggplot2)
library(corrplot)
```

Carga del dataset: subconjuto de entrenamiento. Estudio de los datos tal y como se obtienen de ***Kaggle***. Como veremos los datos están todos en una columna separados por ";".

```{r}
bikes <- read.csv("data/train.csv")
colnames(bikes)
dim(bikes)
```

#### Preprocesado de los datos

En primer lugar, separamos los datos por ";" con el fin de tener las columnas separadas y poder preprocesar y análizar correctamente los datos. La función *summary* nos ofrece un resumen por cada una de las variables presentes en el dataset.

```{r}
train_bikes <- read.table("data/train.csv", na.strings="", header=TRUE, sep=";", dec=".")
head(train_bikes)
colnames(train_bikes)
dim(train_bikes)
summary(train_bikes)
```

Como podemos observar el atributo id no aporta información relevante, por lo que vamos a proceder a eliminarlo. Por otro lado, el atributo count no tiene un nombre representativo, lo sustituiremos por num_bikes.

```{r}
train_bikes <- select(train_bikes, -id)
names(train_bikes)[11] <- "num_bikes"
head(train_bikes)
```

Tras estudiar las variables presentes en el conjunto de datos procedemos a la limpieza de los datos. El objetivo es encontrar valores perdidos (NA).

```{r}
# Preprocesamiento 1. Valores perdidos

# Búsqueda de valores NA
vis_miss(train_bikes);
# Esta función filtraría todos los ejemplos incompletos, si hubiera.
train_bikes <- train_bikes %>%
  filter(complete.cases(train_bikes))
```

En cuanto a la detección y eliminación de outliers, el primer paso es visualizar los valores que contienen ruido a través de una gráfica. Las columnas que estudiamos son aquellas que su valor no está limitado ( *temperatura, temperatura media, humedad, velocidad del viento*).

```{r}
# Preprocesamiento 2. Detección y eliminación de outliers
train_bikes_boxplot <- select(train_bikes, temp, atemp, humidity, windspeed)
boxplot(train_bikes_boxplot, col = rainbow(ncol(train_bikes_boxplot)))
boxplot.stats(train_bikes$windspeed)
```

La velocidad del viento (windspeed) es el único atributo que presenta outliers, por lo que se procede a eliminarlos.

```{r}
# Outliers en windspeed por encima de 32 km/h
outlier_min <- min(boxplot.stats(train_bikes$windspeed)$out)

bikes_without_liers <- train_bikes$windspeed[train_bikes$windspeed < outlier_min]

# Comprobación
boxplot(bikes_without_liers, horizontal = TRUE)
boxplot.stats(bikes_without_liers)

# Filtrado de dataframe
train_bikes <- filter(train_bikes, train_bikes$windspeed < outlier_min)

str(train_bikes)
head(train_bikes)
```

A pesar de que no hay outliers en la variable humedad, es un factor que puede afectar a la salud en un porcentaje menor al 30%. Por ello, vamos a eliminar todos los ejemplos cuya [humedad](https://es.wikipedia.org/wiki/Humedad_relativa) registrada sea menor a esta.

```{r}
# Filtrado de dataframe
train_bikes <- filter(train_bikes, train_bikes$humidity > 30)

# Comprobación
boxplot(train_bikes$humidity, horizontal = TRUE)
```

Respecto al resto de variables que contiene el dataset, se debe comprobar que todos los ejemplos poseen valores dentro del rango permitido.

```{r}
range(train_bikes$year)
range(train_bikes$hour)
range(train_bikes$season)
range(train_bikes$holiday)
range(train_bikes$workingday)
range(train_bikes$weather)
```

Dataframe preprocesado para identificación de valores perdidos, detección y eliminación de outliersy comprobación del rango en variables estáticas.

```{r}
summary(train_bikes)
```

A continuación, se realiza el preprocesamiento para los datos de testeo.

```{r}
test_bikes <- read.table("data/test.csv", na.strings="", header=TRUE, sep=";", dec=".")
head(test_bikes)
colnames(test_bikes)
dim(test_bikes)
```

Eliminamos la columna id, ya que no aporta ningún valor en el testeo.

```{r}
test_bikes <- select(test_bikes, -id)
head(test_bikes)
```

Realizamos una búsqueda de valores indefinidos.

```{r}
# Preprocesamiento 1. Valores perdidos

# Búsqueda de valores NA
vis_miss(test_bikes);
# Esta función filtraría todos los ejemplos incompletos, si hubiera.
test_bikes <- test_bikes %>%
  filter(complete.cases(test_bikes))
```

```{r}
# Preprocesamiento 2. Detección y eliminación de outliers
test_bikes_boxplot <- select(test_bikes, temp, atemp, humidity, windspeed)
boxplot(test_bikes_boxplot, col = rainbow(ncol(test_bikes_boxplot)))
boxplot.stats(test_bikes$windspeed)
```

```{r}
# Outliers en windspeed por encima de 32 km/h
outlier_min <- min(boxplot.stats(test_bikes$windspeed)$out)

test_bikes_without_liers <- test_bikes$windspeed[test_bikes$windspeed < outlier_min]

# Comprobación
boxplot(test_bikes_without_liers, horizontal = TRUE)
boxplot.stats(test_bikes_without_liers)

# Filtrado de dataframe
test_bikes <- filter(test_bikes, test_bikes$windspeed < outlier_min)

str(test_bikes)
head(test_bikes)
```

Al igual que anteriormente, eliminamos los ejemplos cuya [humedad](https://es.wikipedia.org/wiki/Humedad_relativa) sea inferior a 30.

```{r}
# Filtrado de dataframe
test_bikes <- filter(test_bikes, test_bikes$humidity > 30)

# Comprobación
boxplot(test_bikes$humidity, horizontal = TRUE)
```

```{r}
range(test_bikes$year)
range(test_bikes$hour)
range(test_bikes$season)
range(test_bikes$holiday)
range(test_bikes$workingday)
range(test_bikes$weather)
```

```{r}
summary(test_bikes)
```

#### Análisis y visualización de los datos

Comprobamos la homogeneidad de los datos: ¿Cuál es el registro de datos recopilados según la hora? ¿Cuál es el registro de datos recopilados según la temporada del año?

Observaremos que durante la temporada de vacaciones es menos probable que se alquilen bicicletas y por ello, es más complejo recopilar los datos de esos días. Por otro lado, el tiempo también influye en el dataset, para el peor temporal encontramos muchos menos registros.

```{r}
# Ejemplos disponibles según el año
train_bikes %>%
  group_by(year) %>% 
  count()

# Ejemplos disponibles según la hora del día
train_bikes %>%
  group_by(hour) %>% 
  count()

# Ejemplos disponibles según la temporada del año
train_bikes %>%
  group_by(season) %>% 
  count()

# Ejemplos disponibles para vacaciones
train_bikes %>%
  group_by(holiday) %>% 
  count()

# Ejemplos disponibles para días de trabajo
train_bikes %>%
  group_by(workingday) %>% 
  count()

# Ejemplos disponibles según el tiempo
train_bikes %>%
  group_by(weather) %>% 
  count()

```

¿Cuántas bicicletas se han alquilado según la hora del día?

```{r}
bikes_by_hour <- train_bikes %>%
  group_by(hour) %>%
  summarize(total_bikes_by_hour = sum(num_bikes))
  
ggplot(bikes_by_hour, aes(x = hour, y = total_bikes_by_hour)) +
  geom_bar(stat = "identity")
```

¿Cuántas bicicletas se han alquilado según la temporada del año?

```{r}
bikes_by_season <- train_bikes %>%
  group_by(season) %>%
  summarize(total_bikes_by_season = sum(num_bikes))
  
ggplot(bikes_by_season, aes(x = season, y = total_bikes_by_season)) +
  geom_bar(stat = "identity")
```

¿Cuántas bicicletas se han alquilado según el temporal?

```{r}
bikes_by_weather <- train_bikes %>%
  group_by(weather) %>%
  summarize(total_bikes_by_weather = sum(num_bikes))
  
ggplot(bikes_by_weather, aes(x = weather, y = total_bikes_by_weather)) +
  geom_bar(stat = "identity")
```

Porcentaje de bicicletas que se alquilan durante los días de trabajo.

```{r}

bikes_by_working_day <- train_bikes %>%
  group_by(workingday) %>%
  summarize(total_bikes_by_working_day = sum(num_bikes))

bike_count <- bikes_by_working_day$total_bikes_by_working_day

bike_percentage <- paste0(round(100 * bike_count/sum(bike_count), 2), "%")
bike_count
bike_percentage

pie(bike_count, labels = bike_percentage)

legend("topleft", legend = c( "No laboral", "Laboral"), fill =  c("white", "lightblue"))
```

Porcentaje medio de bicicletas que se alquilan si estamos en días de vacaciones o no.

```{r}

bikes_by_holiday <- train_bikes %>%
  group_by(holiday) %>%
  summarize(total_bikes_by_holiday = sum(num_bikes))

bike_count <- bikes_by_holiday$total_bikes_by_holiday

samples_holiday <- train_bikes %>%
                    group_by(holiday) %>% 
                      count()

a_no_holiday <- bike_count[1]/samples_holiday[1,2]

a_holiday <- bike_count[2]/samples_holiday[2,2]

a_bike_count <- data.frame(c(a_no_holiday, a_holiday))

bike_percentage <- paste0(round(100 * a_bike_count/sum(a_bike_count), 2), "%")

result <- data.frame(bike_percentage[1], bike_percentage[2])
colnames(result) <- c("non vacation", "vacation")

result
```

## Algoritmo lm()

El conjunto de datos que se está tratando contiene más de dos variables cuantitativas que se deben emplear en la predicción de bicicletas. Para aplicar un modelo de regresión lineal multivariable es necesario realizar un estudio de la relación lineal existente entre las variables, en concreto el número de bicicletas (variable a predecir) en función del resto de columnas. El análisis comienza con la creación de un diagrama de dispersión que nos muestra la relación entre las variables.

```{r}
# Diagrama de dispersión para el número de bicicletas prente al resto de variables

plot(num_bikes ~ ., train_bikes)
```

Observamos que no es adecuado aplicar modelos de regresión lineal, pues la distrubución no parece indicar una posible relación lineal entre las variables. A pesar de ello, estudiamos la [correlación](https://www.cienciadedatos.net/documentos/24_correlacion_y_regresion_lineal) entre las variables para conocer como de relacionadas están las columnas.

Todos los valores del índice de correlación r varían entre [-1, 1], siendo -1 una correlación negativa perfecta y el 1 correlación positiva perfecta.

-   correlación **nula**: r \< \|0.1\|

-   correlación **pequeña**: \|0.1\| \< r \<= \|0.3\|

-   correlación **mediana** : \|0.3\| \< r \<= \|0.5\|

-   correlación **moderada** : \|0.5\| \< r \<= \|0.7\|

-   correlación **alta o muy alta**: r \> \|0.7\|

```{r}
# Estudio de la normalización de las variables
qqnorm(train_bikes$num_bikes, main = "Num bikes", col = "darkred")
qqline(train_bikes$num_bikes)
qqnorm(train_bikes$hour, main = "Hour", col = "blue")
qqline(train_bikes$hour)
```

Debido a que las variables cuantitativas que contiene el dataset no se distrubuyen de forma normal. Se ha empleado el coeficiente de Spearman para el cálculo de la correlación.

```{r}
# Matriz de correlación entre las variables cuantitativas
cor_datos_cuanti <- round(cor(train_bikes,  method = "spearman"), digits = 2)
cor_datos_cuanti

M <- round(cor(train_bikes,  method = "spearman"), digits=2)

corrplot(M, method = "number", tl.cex = 0.7,number.cex = 0.8)  

```

Al examinar el mapa con los valores de la correlación tenemos que el mayor r obtenido es de 0.53, correlación moderada entre horas y número de bicicletas.

Aunque aplicar un modelo de regresión lineal no tiene sentido para este conjunto de datos, se va generar el modelo lineal a modo de estudio del problema, con el fin de demostar que no aporta valor realizar una predicción de este tipo. En la siguiente sección, se indagará sobre modelos de regresión no lineal obteniendo unos mejores resultados.

```{r}
# Construcción del modelo en base al resto de variables 
lm_bikes <- lm(num_bikes ~ ., data = train_bikes)

# Resumen del modelo
summary(lm_bikes)
```

Analizando el resumen del modelo, encontramos que *holiday*, *workingday*, *weather*, *temp* tienen bajo nivel de significancia. Por ello, vamos a omitir estas columnas tanto en la generación del modelo como en la posterior predicción.

```{r}
train_bikes_short <- select(train_bikes, -holiday, -workingday, -weather, -temp)

head(train_bikes_short)
```

A pesar de eliminar estos atributos poco significativos, el valor de R-squared no varía.

```{r}
# Construcción del modelo en base al resto de variables 
lm_bikes_short <- lm(num_bikes ~ ., data = train_bikes_short)

# Resumen del modelo
summary(lm_bikes_short)
```

```{r}
plot(lm_bikes_short$fitted.values,  lm_bikes_short$residuals,
     xlab = "Valores ajustados", ylab = "Residuos")
```

```{r}
qqnorm(lm_bikes_short$residuals, ylab = "Cuantiles residuales")
```

Realizamos la predicción del número de bicicletas con el primer ejemplo del dataset.

```{r}
# Predecimos el número de bicicletas del primer ejemplo del dataset
sample_1 <- train_bikes %>%
  slice_head(n = 1) %>%
  select(-holiday, -workingday, -weather, -temp)

expected_value <- train_bikes %>%
                    slice_head(n = 1)
  
expected_value[1, 11]
predict(lm_bikes_short, sample_1)

```

## Algoritmos Caret

En este punto, vamos a generar distintos modelos con varios métodos que incluye el paquete Caret. A partir de estos modelos, los cuales son creados a partir del subconjunto de entrenamiento, se procederá a la predicción del número de bicicletas alquiladas para cada uno de los ejemplos del subconjunto de prueba.

Antes de comenzar, se carga el paquete Caret.

```{r}
library(caret)
```

A continuación, creamos la función de control mediante `trainControl`. Con esta función vamos a controlar cómo se crearán los modelos.

```{r}
fitControl <- trainControl(
  method = "cv",
  number = 10,
  savePredictions = TRUE,
  verbose = FALSE
)
```

Con esto, tomaremos el subconjunto de entrenamiento, el cual se usará para preparar los distintos modelos generados con el paquete Caret.

```{r}
head(train_bikes)
```

### Random Forest

Acto seguido, se procede a crear un primer modelo de regresión, utilizando el método Random Forest.

```{r}
model_rf_reg <- train(num_bikes ~ .,
                      train_bikes,
                      method = "rf",
                      ntree = 5,
                      trControl = fitControl)

model_rf_reg
```

### xgbTree

```{r}
model_xgbTree <- train(
  num_bikes ~ .,
  bikes_train_set,
  method = "xgbTree",
  trControl = fitControl)
```

```{r}
model_xgbTree
```

### glmnet

```{r}
model_glmnet_reg <- train(
  num_bikes ~ .,
  bikes_train_set,
  tuneGrid = expand.grid(alpha = 0:1, lambda = seq(0.0001, 1, length = 20)),
  method = "glmnet",
  trControl = fitControl)

model_glmnet_reg
```

## Comparativa de modelos
